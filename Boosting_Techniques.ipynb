{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Boosting Techniques"
      ],
      "metadata": {
        "id": "HS0v29WmHez4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Boosting in Machine Learning? Explain how it improves weak\n",
        "learners."
      ],
      "metadata": {
        "id": "7c1VRKE0Heww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "Boosting is an **ensemble learning technique** in machine learning where multiple **weak learners** (usually decision trees with shallow depth) are combined to create a **strong learner**.\n",
        "\n",
        "A *weak learner* is a model that performs only slightly better than random guessing. Boosting improves these weak learners by training them **sequentially**, not independently.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "1. The first weak learner is trained on the full dataset.\n",
        "2. The algorithm then **checks which samples were misclassified** and gives those samples **higher weights**.\n",
        "3. The next weak learner focuses more on these hard-to-classify samples.\n",
        "4. This process continues, and each new model corrects the mistakes of the previous one.\n",
        "5. Finally, all weak learners are combined (usually by weighted voting or averaging) to form one strong model with much higher accuracy.\n",
        "\n",
        "Because each model **learns from the errors** of the earlier ones, boosting reduces bias and significantly improves overall performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "-jHzPDbRIPtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the difference between AdaBoost and Gradient Boosting in terms\n",
        "of how models are trained?"
      ],
      "metadata": {
        "id": "SH2Gn3bdHet-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Answer:**\n",
        "The main difference between **AdaBoost** and **Gradient Boosting** is how they train their next weak learner.\n",
        "\n",
        "**AdaBoost** increases the **weights of wrongly classified samples** after each iteration. This means the next model focuses more on the difficult points that previous models got wrong. It tries to reduce weighted classification error.\n",
        "\n",
        "**Gradient Boosting**, on the other hand, trains each new model on the **residuals (errors)** of the previous model. Instead of changing sample weights, it uses **gradient descent** to minimize a loss function by correcting the previous model’s mistakes step by step.\n",
        "\n",
        "**In short:**\n",
        "\n",
        "* **AdaBoost:** Fix mistakes by changing *sample weights*.\n",
        "* **Gradient Boosting:** Fix mistakes by modeling *residuals* using gradient descent.\n"
      ],
      "metadata": {
        "id": "ut5Nh7S2I3ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: How does regularization help in XGBoost?\n"
      ],
      "metadata": {
        "id": "MhL1-yeuHeqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer: How regularization helps in XGBoost**\n",
        "\n",
        "Regularization in XGBoost (L1 and L2) helps **control the complexity of the trees**, preventing the model from becoming too large or too deep. It penalizes overly complex trees with too many leaves or large leaf weights.\n",
        "\n",
        "Because of this:\n",
        "\n",
        "* The model avoids **overfitting**\n",
        "* It becomes **more generalizable** to new data\n",
        "* It encourages **simpler, more stable trees**\n",
        "\n",
        "**In simple words:**\n",
        "Regularization in XGBoost makes the model more balanced by preventing it from learning too much noise from the training data.\n"
      ],
      "metadata": {
        "id": "mf-Tiv0_JBhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Why is CatBoost considered efficient for handling categorical data?\n"
      ],
      "metadata": {
        "id": "at1PX_7uHemQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer: **\n",
        "CatBoost is efficient for categorical data because it **automatically converts categorical features into numeric values using Target-based encoding**, but in a safe way that avoids target leakage. It uses a special technique called **Ordered Encoding**, which processes data in a specific order so the model never sees the target value of the current sample.\n",
        "\n",
        "It also uses **built-in handling** of categorical features, so we don’t need manual encoding like one-hot or label encoding. This reduces preprocessing, avoids expanding the dataset, and improves accuracy.\n",
        "\n",
        "**In simple words:**\n",
        "CatBoost is efficient because it directly understands categorical variables and converts them smartly, making training faster and reducing errors.\n"
      ],
      "metadata": {
        "id": "6-TxEkVkJK_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some real-world applications where boosting techniques are\n",
        "preferred over bagging methods?\n",
        "\n",
        "Datasets:\n",
        "\n",
        "● Use sklearn.datasets.load_breast_cancer() for classification tasks.\n",
        "\n",
        "● Use sklearn.datasets.fetch_california_housing() for regression\n",
        "tasks."
      ],
      "metadata": {
        "id": "YoXtvfp_Hei_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "Boosting techniques (like AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost) are preferred in situations where **high accuracy, strong feature interaction handling, and performance on complex patterns** are required. Unlike Bagging—which reduces variance—Boosting focuses on **reducing bias** and correcting mistakes made by earlier models. This makes Boosting more suitable for difficult, noise-free, and highly imbalanced problems.\n",
        "\n",
        "#### **Real-World Applications of Boosting**\n",
        "\n",
        "1. **Fraud Detection (Banking & Finance)**\n",
        "   Boosting models perform extremely well on fraud detection because they focus on **misclassified cases**, which is crucial when fraudulent transactions are rare but important.\n",
        "\n",
        "2. **Customer Churn Prediction (Telecom & SaaS)**\n",
        "   Boosting can pick up subtle patterns in user behavior and interactions, giving higher accuracy than bagging methods.\n",
        "\n",
        "3. **Medical Diagnosis (Classification)**\n",
        "   For datasets like *breast cancer classification*, Boosting often outperforms bagging due to its ability to capture complex non-linear relations and reduce bias.\n",
        "\n",
        "4. **Credit Risk Scoring (Loan Defaults)**\n",
        "   Banks rely on boosting models to assign credit scores because they handle **imbalanced datasets** and detect risky customers more accurately.\n",
        "\n",
        "5. **Search Ranking & Recommendations (Tech companies)**\n",
        "   XGBoost and LightGBM are widely used in ranking systems like:\n",
        "\n",
        "   * YouTube Recommendations\n",
        "   * Google Search\n",
        "   * E-commerce product ranking\n",
        "\n",
        "6. **Insurance Claim Prediction**\n",
        "   Boosting models help estimate the probability and size of claims by capturing complex relationships in customer profiles.\n",
        "\n",
        "7. **Demand Forecasting (Retail & Supply Chain)**\n",
        "   Gradient Boosting and XGBoost handle seasonal and non-linear trends better than bagging algorithms.\n",
        "\n",
        "8. **House Price Prediction (Regression)**\n",
        "   For datasets like *California Housing*, Boosting reduces bias and provides more accurate predictions compared to Random Forest.\n",
        "\n",
        "\n",
        "\n",
        "### **In summary:**\n",
        "\n",
        "Boosting is preferred when the dataset is complex, slightly noisy, or imbalanced—and when we need the **highest accuracy** and better handling of **hard-to-predict cases**. Bagging is simpler and more stable, but Boosting usually wins in high-performance machine learning tasks.\n"
      ],
      "metadata": {
        "id": "bRg_zbazJfh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "\n",
        "● Train an AdaBoost Classifier on the Breast Cancer dataset\n",
        "\n",
        "● Print the model accuracy\n"
      ],
      "metadata": {
        "id": "Xz4IKjPNHefm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "ada = AdaBoostClassifier(n_estimators=100, learning_rate=0.8, random_state=42)\n",
        "\n",
        "ada.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ada.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"AdaBoost Classifier Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCulSmlwJrF1",
        "outputId": "e5716064-6800-477d-b291-b4c445e9ec8e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "\n",
        "● Train a Gradient Boosting Regressor on the California Housing dataset\n",
        "\n",
        "● Evaluate performance using R-squared score\n"
      ],
      "metadata": {
        "id": "Zoqu6dmiHeYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "gbr = GradientBoostingRegressor(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = gbr.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Gradient Boosting Regressor R² Score:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPI7nDSbJ4v0",
        "outputId": "44407b3d-6755-49a1-ab78-ec9502a9b35a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor R² Score: 0.8004451261281281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "\n",
        "● Train an XGBoost Classifier on the Breast Cancer dataset\n",
        "\n",
        "● Tune the learning rate using GridSearchCV\n",
        "\n",
        "● Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "yRdYvWsYH6x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=3,\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Test Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMFzoTsvKRs7",
        "outputId": "838f4c51-607d-4a6e-8b4e-6b485c6dbaf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.1}\n",
            "Test Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "\n",
        "● Train a CatBoost Classifier\n",
        "\n",
        "● Plot the confusion matrix using seaborn"
      ],
      "metadata": {
        "id": "qC5OsyrHH-GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KaVdrlThKtNs",
        "outputId": "f2b86323-8fe5-4696-e193-30935f11ba0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = CatBoostClassifier(\n",
        "    iterations=300,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - CatBoost Classifier\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "AW9n-piHKfEL",
        "outputId": "02df8ee8-3942-44f5-a483-54e18c45d255"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You're working for a FinTech company trying to predict loan default using\n",
        "customer demographics and transaction behavior.\n",
        "The dataset is imbalanced, contains missing values, and has both numeric and\n",
        "categorical features.\n",
        "\n",
        "Describe your step-by-step data science pipeline using boosting techniques:\n",
        "\n",
        "● Data preprocessing & handling missing/categorical values\n",
        "\n",
        "● Choice between AdaBoost, XGBoost, or CatBoost\n",
        "\n",
        "● Hyperparameter tuning strategy\n",
        "\n",
        "● Evaluation metrics you'd choose and why\n",
        "\n",
        "● How the business would benefit from your model"
      ],
      "metadata": {
        "id": "j2E6MVKpIBa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Loan Default Prediction Pipeline using Boosting Techniques\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Generate Synthetic Dataset\n",
        "# -----------------------------\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=5000,\n",
        "    n_features=15,\n",
        "    n_informative=10,\n",
        "    n_classes=2,\n",
        "    weights=[0.85, 0.15],   # imbalanced\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "data = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(15)])\n",
        "data[\"default\"] = y\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(\"default\", axis=1)\n",
        "y = data[\"default\"]\n",
        "\n",
        "numeric_cols = X.select_dtypes(include=['int64', 'float64', 'float32']).columns\n",
        "categorical_cols = []  # Synthetic data has no categorical features\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# 2. Preprocessing Pipelines for numeric + categorical data\n",
        "# --------------------------------------------------------\n",
        "numeric_transform = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transform, numeric_cols)\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Train-Test Split\n",
        "# ------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Handle Imbalance Using SMOTE\n",
        "# ------------------------------\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# ------------------------------\n",
        "# 5A. Model 1 — XGBoost Pipeline\n",
        "# ------------------------------\n",
        "xgb_model = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"clf\", XGBClassifier(\n",
        "        eval_metric=\"logloss\",\n",
        "        use_label_encoder=False,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning\n",
        "xgb_params = {\n",
        "    \"clf__learning_rate\": [0.01, 0.1],\n",
        "    \"clf__max_depth\": [3, 5],\n",
        "    \"clf__n_estimators\": [100, 200]\n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(xgb_model, xgb_params, cv=3, scoring=\"roc_auc\")\n",
        "grid_xgb.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"\\nBest XGBoost Params:\", grid_xgb.best_params_)\n",
        "\n",
        "# Predictions\n",
        "xgb_pred = grid_xgb.predict(X_test)\n",
        "xgb_proba = grid_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nXGBoost Classification Report:\\n\")\n",
        "print(classification_report(y_test, xgb_pred))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, xgb_proba))\n",
        "\n",
        "# ------------------------------\n",
        "# 5B. Model 2 — CatBoost\n",
        "# ------------------------------\n",
        "cat_model = CatBoostClassifier(\n",
        "    loss_function=\"Logloss\",\n",
        "    random_seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# CatBoost handles missing + categorical automatically\n",
        "cat_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "cat_pred = cat_model.predict(X_test)\n",
        "cat_proba = cat_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nCatBoost Classification Report:\\n\")\n",
        "print(classification_report(y_test, cat_pred))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, cat_proba))\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Confusion Matrix\n",
        "# ------------------------------\n",
        "print(\"\\nConfusion Matrix (CatBoost):\")\n",
        "print(confusion_matrix(y_test, cat_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnlQhInLLivC",
        "outputId": "9dd1d0c7-a22b-4bba-f9c3-f5307bbd8311"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:37:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best XGBoost Params: {'clf__learning_rate': 0.1, 'clf__max_depth': 5, 'clf__n_estimators': 200}\n",
            "\n",
            "XGBoost Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1056\n",
            "           1       0.90      0.88      0.89       194\n",
            "\n",
            "    accuracy                           0.97      1250\n",
            "   macro avg       0.94      0.93      0.94      1250\n",
            "weighted avg       0.97      0.97      0.97      1250\n",
            "\n",
            "ROC AUC Score: 0.9718496173070916\n",
            "\n",
            "CatBoost Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      1056\n",
            "           1       0.93      0.89      0.91       194\n",
            "\n",
            "    accuracy                           0.97      1250\n",
            "   macro avg       0.95      0.94      0.95      1250\n",
            "weighted avg       0.97      0.97      0.97      1250\n",
            "\n",
            "ROC AUC Score: 0.9776485863792566\n",
            "\n",
            "Confusion Matrix (CatBoost):\n",
            "[[1042   14]\n",
            " [  21  173]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LSkvqc7HZP7"
      },
      "outputs": [],
      "source": []
    }
  ]
}