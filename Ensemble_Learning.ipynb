{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Learning"
      ],
      "metadata": {
        "id": "h8AeFRd50gcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment Questions"
      ],
      "metadata": {
        "id": "wDnq5eT80n2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Can we use Bagging for regression problems?\n",
        "\n",
        "Answer - Yes, Bagging can be used for regression.\n",
        "In regression, multiple regression models (like Decision Trees) are trained on different bootstrap samples. Each model gives a numerical prediction, and Bagging takes the average of all these predictions.\n",
        "This helps reduce variance and makes the model more stable."
      ],
      "metadata": {
        "id": "TLRWPMDE0wcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. What is the difference between multiple model training and single model training?\n",
        "\n",
        " Answer - Single model training means using only one algorithm to learn from the data. Its performance depends completely on that one model.\n",
        "\n",
        "Multiple model training (Ensemble learning) trains several models on different parts or views of the data and combines their predictions.\n",
        "This usually gives better generalization, more accuracy, and reduces overfitting."
      ],
      "metadata": {
        "id": "ZBUj44QB0wYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain the concept of feature randomness in Random Forest?\n",
        "\n",
        "Answer - Random Forest adds randomness by selecting a random subset of features at each split instead of checking all features.\n",
        "\n",
        "This ensures that all trees are not identical and that each tree learns different patterns from the data.\n",
        "\n",
        "This randomness improves performance and reduces overfitting."
      ],
      "metadata": {
        "id": "Nrmqp2Ua0wUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is OOB (Out-of-Bag) Score?\n",
        "\n",
        "Answer - OOB score is a built-in validation method used in Bagging and Random Forest.\n",
        "Since each tree trains on a bootstrap sample, around 37% of data is left out automatically.\n",
        "This unseen data is used to test the tree’s performance.\n",
        "The OOB score gives an unbiased estimate without needing a separate test set."
      ],
      "metadata": {
        "id": "fAsiBJuy0wQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How can you measure the importance of features in a Random Forest model?\n",
        "\n",
        "Answer - Two main methods are used:\n",
        "\n",
        "1. Gini Importance – Measures how much each feature reduces impurity in splits across all trees.\n",
        "\n",
        "2. Permutation Importance – Checks how accuracy drops when a feature’s values are randomly shuffled.\n",
        "Higher drop = more important feature."
      ],
      "metadata": {
        "id": "23vWPTWD0wM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the working principle of a Bagging Classifier?\n",
        "\n",
        "Answer - Bagging works by:\n",
        "\n",
        "1. Creating many different bootstrap samples from the dataset.\n",
        "\n",
        "2. Training a separate classifier (usually decision trees) on each sample.\n",
        "\n",
        "3. Making predictions by taking a majority vote across all models.\n",
        "This reduces variance and improves stability of the model."
      ],
      "metadata": {
        "id": "mmk9uiIW0wJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How do you evaluate a Bagging Classifier’s performance?\n",
        "\n",
        "Answer - You can evaluate a Bagging Classifier using:\n",
        "\n",
        "* Accuracy\n",
        "\n",
        "* Precision, Recall, F1-Score\n",
        "\n",
        "* Confusion Matrix\n",
        "\n",
        "* Cross-validation\n",
        "\n",
        "OOB score (for Bagging and Random Forest)\n",
        "These metrics help measure how well the ensemble predicts on unseen data."
      ],
      "metadata": {
        "id": "KuwFtS7O0wGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. How does a Bagging Regressor work?\n",
        "\n",
        "Answer - A Bagging Regressor works the same way as Bagging Classifier, but instead of voting, it averages predictions.\n",
        "Each model predicts a number, and the final answer is the mean of all model outputs.\n",
        "This averaging makes the model less sensitive to noise."
      ],
      "metadata": {
        "id": "5PsxlpLT0wCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main advantage of ensemble techniques?\n",
        "\n",
        "Answer - The biggest advantage is high accuracy and robustness.\n",
        "Ensembles combine multiple models, which smooths out individual model errors, reduces overfitting, and gives more reliable predictions."
      ],
      "metadata": {
        "id": "tHcxb2qY0v_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the main challenge of ensemble methods?\n",
        "\n",
        "Answer - They are computationally expensive and harder to interpret.\n",
        "Since many models are trained, they require more time, memory, and processing power.\n",
        "Also, the final model becomes a “black box,” making it difficult to explain decisions."
      ],
      "metadata": {
        "id": "YPVvVmqC1Jjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 11. Explain the key idea behind ensemble techniques?\n",
        "\n",
        " Answer - The main idea is:\n",
        "“Combining many weak or average models gives one strong model.”\n",
        "Each model captures different patterns, and their collective decision boosts performance."
      ],
      "metadata": {
        "id": "WuAvJuFX1Jar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is a Random Forest Classifier?\n",
        "\n",
        "Answer - Random Forest is an ensemble of many decision trees.\n",
        "Each tree is trained on a different bootstrap sample and uses random feature selection.\n",
        "The final class prediction is made using majority voting across all trees.\n",
        "It is powerful, stable, and widely used."
      ],
      "metadata": {
        "id": "V_3VgJHc1JUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are the main types of ensemble techniques?\n",
        "\n",
        "Answer - Bagging – Reduces variance (Random Forest).\n",
        "\n",
        "Boosting – Reduces bias by learning from previous mistakes (AdaBoost, XGBoost).\n",
        "\n",
        "Stacking – Combines different models using a meta-learner."
      ],
      "metadata": {
        "id": "8aJyjsrm1JQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is ensemble learning in machine learning?\n",
        "\n",
        "Answer - Ensemble learning is a method where multiple models are combined to produce better predictions than a single model.\n",
        "It improves accuracy, stability, and generalization across tasks."
      ],
      "metadata": {
        "id": "LBR3g5DG1HpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. When should we avoid using ensemble methods?\n",
        "\n",
        "Answer - Avoid them when:\n",
        "\n",
        "* The dataset is small.\n",
        "\n",
        "* You need simple and interpretable models.\n",
        "\n",
        "* You have limited computation power.\n",
        "\n",
        "* Training time must be very low."
      ],
      "metadata": {
        "id": "kc2X1quY0v75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How does Bagging help in reducing overfitting?\n",
        "\n",
        "Answer - Bagging reduces overfitting by training each model on different bootstrap samples.\n",
        "Since the models learn different patterns, combining them reduces variance and makes predictions more stable and less noisy."
      ],
      "metadata": {
        "id": "fxyIN0KH1Ytl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Why is Random Forest better than a single Decision Tree?\n",
        "\n",
        "Answer - A single tree easily overfits\n",
        "\n",
        "Random Forest reduces overfitting using bagging\n",
        "\n",
        "Uses random feature selection for diversity\n",
        "\n",
        "More accurate and robust\n",
        "\n",
        "Handles noise better\n",
        "This makes Random Forest more reliable in real-world applications."
      ],
      "metadata": {
        "id": "wH_ZNKch1bfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the role of bootstrap sampling in Bagging?\n",
        "\n",
        "Answer - Bootstrap sampling creates multiple random subsets of data with replacement.\n",
        "Each subset trains a different model.\n",
        "This increases model diversity and improves final accuracy."
      ],
      "metadata": {
        "id": "un2qqqsJ1dk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What are some real-world applications of ensemble techniques?\n",
        "\n",
        "Answer -\n",
        "* raud detection\n",
        "\n",
        "* Loan default prediction\n",
        "\n",
        "* Customer churn\n",
        "\n",
        "* Medical diagnosis\n",
        "\n",
        "* Spam detection\n",
        "\n",
        "* Stock market predictions\n",
        "\n",
        "* Credit scoring\n",
        "\n",
        "* Recommendation systems\n",
        "\n",
        "Ensembles work well wherever accuracy is important."
      ],
      "metadata": {
        "id": "ZXXbjWfw1gLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 20. What is the difference between Bagging and Boosting?\n",
        "\n",
        " Answer - Bagging\n",
        "\n",
        "* Trains models in parallel\n",
        "\n",
        "* Focuses on reducing variance\n",
        "\n",
        "* Each model is independent\n",
        "\n",
        "Examples: Bagging Classifier, Random Forest\n",
        "\n",
        "Boosting\n",
        "\n",
        "* Trains models sequentially\n",
        "\n",
        "* Focuses on reducing bias\n",
        "\n",
        "* Each model learns from previous model's errors\n",
        "\n",
        "Examples: AdaBoost, XGBoost, Gradient Boosting"
      ],
      "metadata": {
        "id": "-NqVX4Pf1iwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practical"
      ],
      "metadata": {
        "id": "na7t_ku00v3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy"
      ],
      "metadata": {
        "id": "tnpcqEFP1nEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bag.fit(X_train, y_train)\n",
        "pred = bag.predict(X_test)\n",
        "print(\"Bagging (DT) Accuracy:\", round(accuracy_score(y_test, pred), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fyJJL4i5wSb",
        "outputId": "86a19c80-2305-44e5-9ad1-bffd5e437c98"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging (DT) Accuracy: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)2"
      ],
      "metadata": {
        "id": "Cuxdu1uU1qeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = make_regression(n_samples=800, n_features=15, noise=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "bag_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=40, random_state=42)\n",
        "bag_reg.fit(X_train, y_train)\n",
        "y_pred = bag_reg.predict(X_test)\n",
        "print(\"Bagging Regressor MSE:\", round(mean_squared_error(y_test, y_pred), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9tGf3Qw64X8",
        "outputId": "2325a775-b6d2-4ccf-c673-20dbaa9adc51"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 6483.9789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores"
      ],
      "metadata": {
        "id": "6N0sPrAA1sss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "idx = np.argsort(importances)[::-1]\n",
        "print(\"Top 10 features (name : importance):\")\n",
        "for i in idx[:10]:\n",
        "    print(f\"{data.feature_names[i]} : {round(importances[i], 4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzUN_5hj7DkF",
        "outputId": "8555bf1e-6876-4ab9-bd35-fcd6006aae0f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 features (name : importance):\n",
            "worst area : 0.1394\n",
            "worst concave points : 0.1322\n",
            "mean concave points : 0.107\n",
            "worst radius : 0.0828\n",
            "worst perimeter : 0.0808\n",
            "mean perimeter : 0.068\n",
            "mean concavity : 0.0669\n",
            "mean area : 0.0605\n",
            "worst concavity : 0.0373\n",
            "mean radius : 0.0348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Train a Random Forest Regressor and compare its performance with a single Decision Tree"
      ],
      "metadata": {
        "id": "q7vYLDwr11gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "rf_pred = rf.predict(X_test)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "print(\"Random Forest MSE:\", round(mean_squared_error(y_test, rf_pred), 4))\n",
        "print(\"Decision Tree MSE:\", round(mean_squared_error(y_test, dt_pred), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMz_Ar3E7HQ1",
        "outputId": "5dabca7a-2082-43aa-cae1-cdd7856d46c3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MSE: 0.2554\n",
            "Decision Tree MSE: 0.4952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier"
      ],
      "metadata": {
        "id": "zoxHp6fS1qZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "rf_oob = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
        "rf_oob.fit(X, y)\n",
        "print(\"OOB Score:\", round(rf_oob.oob_score_, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grXZy3BR7P38",
        "outputId": "2ce073cf-b640-4cdb-ff81-d1f25d5bd04f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Train a Bagging Classifier using SVM as a base estimator and print accuracy"
      ],
      "metadata": {
        "id": "bL6WlQT11qV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data[:, :2], data.target  # use 2 features for faster SVM\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "base_svm = SVC(kernel='rbf', probability=False)  # probability not needed for accuracy\n",
        "bag_svm = BaggingClassifier(estimator=base_svm, n_estimators=20, random_state=42)\n",
        "bag_svm.fit(X_train, y_train)\n",
        "print(\"Bagging (SVM) Accuracy:\", round(accuracy_score(y_test, bag_svm.predict(X_test)), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYlEjBC_7Szc",
        "outputId": "5edb0bd5-ad2b-4a6b-f15b-3c772c3b6170"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging (SVM) Accuracy: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Train a Random Forest Classifier with different numbers of trees and compare accuracy"
      ],
      "metadata": {
        "id": "03jBLvtB1qPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "for n in [5, 20, 50, 100, 200]:\n",
        "    rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print(f\"n_estimators={n} -> Accuracy: {round(accuracy_score(y_test, rf.predict(X_test)), 4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_8kX4fB7Yi1",
        "outputId": "03ae9866-36a4-4dba-bdd8-606eb96ed1fa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators=5 -> Accuracy: 0.9649\n",
            "n_estimators=20 -> Accuracy: 0.9708\n",
            "n_estimators=50 -> Accuracy: 0.9708\n",
            "n_estimators=100 -> Accuracy: 0.9708\n",
            "n_estimators=200 -> Accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score"
      ],
      "metadata": {
        "id": "N1yKfSti1pyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "base_lr = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "bag_lr = BaggingClassifier(estimator=base_lr, n_estimators=50, random_state=42)\n",
        "bag_lr.fit(X_train, y_train)\n",
        "\n",
        "probs = bag_lr.predict_proba(X_test)[:, 1]\n",
        "print(\"Bagging (LogReg) AUC:\", round(roc_auc_score(y_test, probs), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjRywojX7bGt",
        "outputId": "0e504a1b-3ea3-4e09-b4d0-86a3cc314399"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging (LogReg) AUC: 0.9982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Train a Random Forest Regressor and analyze feature importance scores"
      ],
      "metadata": {
        "id": "SAmWXa7q0vDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "house = fetch_california_housing()\n",
        "X, y = house.data, house.target\n",
        "rf_reg = RandomForestRegressor(n_estimators=150, random_state=42)\n",
        "rf_reg.fit(X, y)\n",
        "\n",
        "imp = rf_reg.feature_importances_\n",
        "idx = np.argsort(imp)[::-1]\n",
        "print(\"Feature importances (top 8):\")\n",
        "for i in idx[:8]:\n",
        "    print(f\"{house.feature_names[i]} : {round(imp[i], 4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDzYGTPE7uVN",
        "outputId": "1f3483c4-26db-42ba-fccd-8647e6c094fa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importances (top 8):\n",
            "MedInc : 0.5199\n",
            "AveOccup : 0.1367\n",
            "Latitude : 0.0932\n",
            "Longitude : 0.0926\n",
            "HouseAge : 0.0528\n",
            "AveRooms : 0.0444\n",
            "Population : 0.0313\n",
            "AveBedrms : 0.0293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Train an ensemble model using both Bagging and Random Forest and compare accuracy."
      ],
      "metadata": {
        "id": "YwN1Fzy72DRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
        "bag.fit(X_train, y_train)\n",
        "acc_bag = accuracy_score(y_test, bag.predict(X_test))\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "acc_rf = accuracy_score(y_test, rf.predict(X_test))\n",
        "\n",
        "print(\"Bagging (DT) Accuracy:\", round(acc_bag, 4))\n",
        "print(\"Random Forest Accuracy:  \", round(acc_rf, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFA0zyqS70MV",
        "outputId": "5436cc93-7939-4bb9-810f-78b952fbc424"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging (DT) Accuracy: 0.963\n",
            "Random Forest Accuracy:   1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV"
      ],
      "metadata": {
        "id": "pak_gT_K2FXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "grid = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Test accuracy:\", round(accuracy_score(y_test, grid.best_estimator_.predict(X_test)), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhw73fPN73P_",
        "outputId": "62c9af14-90db-4ea5-8f42-85ed942c0123"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "Test accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "32. Train a Bagging Regressor with different numbers of base estimators and compare performance"
      ],
      "metadata": {
        "id": "fYdfEzY82HGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=15, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "for n in [5, 20, 50, 100]:\n",
        "    bag = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42), n_estimators=n, random_state=42)\n",
        "    bag.fit(X_train, y_train)\n",
        "    mse = mean_squared_error(y_test, bag.predict(X_test))\n",
        "    print(f\"n_estimators={n} -> MSE: {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVghUemk8m93",
        "outputId": "c694f02b-efa4-4e87-e34d-0109d32b0208"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators=5 -> MSE: 10104.8609\n",
            "n_estimators=20 -> MSE: 7872.9309\n",
            "n_estimators=50 -> MSE: 7689.2870\n",
            "n_estimators=100 -> MSE: 7327.7839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 33. Train a Random Forest Classifier and analyze misclassified samples"
      ],
      "metadata": {
        "id": "9y09CSzg2Jm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
        "\n",
        "mis_idx = [i for i, (t, p) in enumerate(zip(y_test, y_pred)) if t != p]\n",
        "print(\"Number misclassified:\", len(mis_idx))\n",
        "for i in mis_idx[:10]:\n",
        "    print(f\"Index:{i}, True:{y_test[i]}, Pred:{y_pred[i]}, Features(sample): {X_test[i][:5]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4StKZBo-8pdm",
        "outputId": "a18299c1-c59b-488b-9f7e-6f5c00ced7a5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Number misclassified: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier="
      ],
      "metadata": {
        "id": "hZ3j4hOh2Lbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42), n_estimators=50, random_state=42)\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "bag.fit(X_train, y_train)\n",
        "\n",
        "print(\"Decision Tree acc:\", round(accuracy_score(y_test, dt.predict(X_test)), 4))\n",
        "print(\"Bagging (DT) acc :\", round(accuracy_score(y_test, bag.predict(X_test)), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJpLuVXz8sFj",
        "outputId": "0a66e11a-a465-4c46-bc51-6571893a9c4f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree acc: 0.9415\n",
            "Bagging (DT) acc : 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 35. Train a Random Forest Classifier and visualize the confusion matrix"
      ],
      "metadata": {
        "id": "FFgFNvmM2NW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix'); plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "x056rwy88xEv",
        "outputId": "2eb1750d-481a-403e-dd05-8579634fc937"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy"
      ],
      "metadata": {
        "id": "nHmOXapq2Plj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svm', SVC(kernel='rbf', probability=True, random_state=42))\n",
        "]\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=1000), n_jobs=-1)\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking accuracy:\", round(accuracy_score(y_test, stack.predict(X_test)), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmo8vzx381VP",
        "outputId": "1c76fbee-38e5-47e3-c7f5-8424bf8175b9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking accuracy: 0.963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "37. Train a Random Forest Classifier and print the top 5 most important features"
      ],
      "metadata": {
        "id": "78ZjZ4pd2R8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "imp = rf.feature_importances_\n",
        "top5 = np.argsort(imp)[-5:][::-1]\n",
        "print(\"Top 5 features:\")\n",
        "for i in top5:\n",
        "    print(f\"{data.feature_names[i]} : {imp[i]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR5PjI--9AR_",
        "outputId": "c8f7f6ed-4581-4a48-886b-43467f0b6a3d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 features:\n",
            "worst perimeter : 0.1433\n",
            "worst area : 0.1281\n",
            "worst concave points : 0.1191\n",
            "mean concave points : 0.1022\n",
            "worst radius : 0.0762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score"
      ],
      "metadata": {
        "id": "mio6S5wF2UIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42), n_estimators=100, random_state=42)\n",
        "bag.fit(X_train, y_train)\n",
        "print(classification_report(y_test, bag.predict(X_test), digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZC9gUVm9Cqh",
        "outputId": "b6358af5-05fd-4cad-de0c-29f682763e61"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9516    0.9365    0.9440        63\n",
            "           1     0.9633    0.9722    0.9677       108\n",
            "\n",
            "    accuracy                         0.9591       171\n",
            "   macro avg     0.9575    0.9544    0.9559       171\n",
            "weighted avg     0.9590    0.9591    0.9590       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy"
      ],
      "metadata": {
        "id": "r1D9tP5C2V5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "for depth in [None, 3, 5, 10, 20]:\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print(f\"max_depth={depth} -> acc: {accuracy_score(y_test, rf.predict(X_test)):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI0NUuxX9Egf",
        "outputId": "5d9d2e6b-a272-4785-8db4-fd780cad5483"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth=None -> acc: 1.0000\n",
            "max_depth=3 -> acc: 1.0000\n",
            "max_depth=5 -> acc: 1.0000\n",
            "max_depth=10 -> acc: 1.0000\n",
            "max_depth=20 -> acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare\n",
        "performance"
      ],
      "metadata": {
        "id": "RiKMBPzf2Xrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "for estimator in [DecisionTreeRegressor(random_state=42), KNeighborsRegressor()]:\n",
        "    bag = BaggingRegressor(estimator=estimator, n_estimators=40, random_state=42)\n",
        "    bag.fit(X_train, y_train)\n",
        "    print(f\"{estimator.__class__.__name__} Bagging MSE:\", mean_squared_error(y_test, bag.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpaxvHvy9GlP",
        "outputId": "080a2dbc-9594-4479-b0e4-d9f414926171"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeRegressor Bagging MSE: 7515.853764551843\n",
            "KNeighborsRegressor Bagging MSE: 14350.600322858254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score"
      ],
      "metadata": {
        "id": "xJActs9c2ZR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "probs = rf.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC:\", round(roc_auc_score(y_test, probs), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiyEhnE_9JrK",
        "outputId": "f405f0a2-bf0d-4694-edcf-78a2b8338702"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 0.9972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "42. Train a Bagging Classifier and evaluate its performance using cross-validatio."
      ],
      "metadata": {
        "id": "6WA0x-GQ2bjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
        "scores = cross_val_score(bag, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(\"CV accuracies:\", scores)\n",
        "print(\"CV mean accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSNgP10K9LyR",
        "outputId": "73dc32bb-0b33-4321-fb9d-4728e0700969"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV accuracies: [0.94444444 0.88888889 0.97222222 0.97142857 1.        ]\n",
            "CV mean accuracy: 0.9553968253968254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 43. Train a Random Forest Classifier and plot the Precision-Recall curv\u0010"
      ],
      "metadata": {
        "id": "b_Zdw0Ps2da-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "probs = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, probs)\n",
        "ap = average_precision_score(y_test, probs)\n",
        "plt.plot(recall, precision, label=f'AP={ap:.3f}')\n",
        "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall Curve'); plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "IrpmkeCh9M86",
        "outputId": "d58c399b-4e21-41a4-9fa4-e2507d37c596"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAR2hJREFUeJzt3XlcVXX+x/H35QIXEAGVTYnE3dFcCpPBJZdQFHOyacpc0UlznSkZMy2VspKsNK1MrXGrqcTMGkvDlNLSNMttxlJzwVzBZRIUFYR7fn/049YNMEHgiuf1fDzOQ+/3fs/3fM4X8r47yz0WwzAMAQAAmIibqwsAAACoaAQgAABgOgQgAABgOgQgAABgOgQgAABgOgQgAABgOgQgAABgOgQgAABgOgQgAABgOgQgAEUaNGiQIiIiSrTOunXrZLFYtG7dunKpqbLr2LGjOnbs6Hh96NAhWSwWLVq0yGU1AWZFAAKuE4sWLZLFYnEsXl5eatiwoUaPHq2MjAxXl3fdKwgTBYubm5uqV6+u7t27a9OmTa4ur0xkZGRo7Nixaty4sXx8fFSlShVFRkbqmWee0dmzZ11dHlCpuLu6AADOpkyZojp16ujSpUvasGGD5syZo1WrVmnXrl3y8fGpsDreeOMN2e32Eq1zxx136OLFi/L09Cynqn5fnz59FBcXp/z8fP3www967bXX1KlTJ33zzTdq1qyZy+q6Vt98843i4uJ0/vx59e/fX5GRkZKkb7/9Vs8995y++OILffrppy6uEqg8CEDAdaZ79+5q1aqVJGnIkCGqUaOGZsyYoX//+9/q06dPketkZ2erSpUqZVqHh4dHiddxc3OTl5dXmdZRUrfddpv69+/veN2+fXt1795dc+bM0WuvvebCykrv7Nmzuueee2S1WrV9+3Y1btzY6f1nn31Wb7zxRplsqzx+l4DrEafAgOtc586dJUlpaWmSfr42x9fXVwcOHFBcXJyqVq2qfv36SZLsdrtmzpyppk2bysvLSyEhIRo2bJh++umnQuN+8skn6tChg6pWrSo/Pz/dfvvteueddxzvF3UN0JIlSxQZGelYp1mzZpo1a5bj/eKuAXrvvfcUGRkpb29vBQYGqn///jp27JhTn4L9OnbsmHr16iVfX18FBQVp7Nixys/PL/X8tW/fXpJ04MABp/azZ8/qkUceUXh4uGw2m+rXr69p06YVOuplt9s1a9YsNWvWTF5eXgoKClK3bt307bffOvosXLhQnTt3VnBwsGw2m5o0aaI5c+aUuubfmjdvno4dO6YZM2YUCj+SFBISookTJzpeWywWPfnkk4X6RUREaNCgQY7XBadd169fr5EjRyo4OFg33XSTli1b5mgvqhaLxaJdu3Y52vbs2aO//OUvql69ury8vNSqVSutWLHi2nYaKGccAQKucwUf3DVq1HC05eXlKTY2Vu3atdOLL77oODU2bNgwLVq0SIMHD9bf//53paWl6dVXX9X27du1ceNGx1GdRYsW6a9//auaNm2qCRMmKCAgQNu3b1dKSor69u1bZB1r1qxRnz59dOedd2ratGmSpN27d2vjxo16+OGHi62/oJ7bb79dSUlJysjI0KxZs7Rx40Zt375dAQEBjr75+fmKjY1VVFSUXnzxRa1du1bTp09XvXr1NGLEiFLN36FDhyRJ1apVc7RduHBBHTp00LFjxzRs2DDdfPPN+uqrrzRhwgSdOHFCM2fOdPR98MEHtWjRInXv3l1DhgxRXl6evvzyS23evNlxpG7OnDlq2rSp/vSnP8nd3V0fffSRRo4cKbvdrlGjRpWq7l9bsWKFvL299Ze//OWaxyrKyJEjFRQUpMmTJys7O1s9evSQr6+vli5dqg4dOjj1TU5OVtOmTXXLLbdIkr777ju1bdtWYWFhGj9+vKpUqaKlS5eqV69eev/993XPPfeUS83ANTMAXBcWLlxoSDLWrl1rnDp1yjhy5IixZMkSo0aNGoa3t7dx9OhRwzAMIz4+3pBkjB8/3mn9L7/80pBkvP32207tKSkpTu1nz541qlatakRFRRkXL1506mu32x1/j4+PN2rXru14/fDDDxt+fn5GXl5esfvw+eefG5KMzz//3DAMw8jNzTWCg4ONW265xWlbH3/8sSHJmDx5stP2JBlTpkxxGvPWW281IiMji91mgbS0NEOS8dRTTxmnTp0y0tPTjS+//NK4/fbbDUnGe++95+j79NNPG1WqVDF++OEHpzHGjx9vWK1W4/Dhw4ZhGMZnn31mSDL+/ve/F9rer+fqwoULhd6PjY016tat69TWoUMHo0OHDoVqXrhw4RX3rVq1akaLFi2u2OfXJBmJiYmF2mvXrm3Ex8c7Xhf8zrVr167Qz7VPnz5GcHCwU/uJEycMNzc3p5/RnXfeaTRr1sy4dOmSo81utxtt2rQxGjRocNU1AxWNU2DAdSYmJkZBQUEKDw/XAw88IF9fX33wwQcKCwtz6vfbIyLvvfee/P391aVLF50+fdqxREZGytfXV59//rmkn4/knDt3TuPHjy90vY7FYim2roCAAGVnZ2vNmjVXvS/ffvutTp48qZEjRzptq0ePHmrcuLFWrlxZaJ3hw4c7vW7fvr0OHjx41dtMTExUUFCQQkND1b59e+3evVvTp093Onry3nvvqX379qpWrZrTXMXExCg/P19ffPGFJOn999+XxWJRYmJioe38eq68vb0df8/MzNTp06fVoUMHHTx4UJmZmVdde3GysrJUtWrVax6nOEOHDpXVanVq6927t06ePOl0OnPZsmWy2+3q3bu3JOl///ufPvvsM91///06d+6cYx7PnDmj2NhY7du3r9CpTuB6wSkw4Doze/ZsNWzYUO7u7goJCVGjRo3k5ub8/yru7u666aabnNr27dunzMxMBQcHFznuyZMnJf1ySq3gFMbVGjlypJYuXaru3bsrLCxMXbt21f33369u3boVu86PP/4oSWrUqFGh9xo3bqwNGzY4tRVcY/Nr1apVc7qG6dSpU07XBPn6+srX19fx+qGHHtJ9992nS5cu6bPPPtPLL79c6Bqiffv26T//+U+hbRX49VzVqlVL1atXL3YfJWnjxo1KTEzUpk2bdOHCBaf3MjMz5e/vf8X1f4+fn5/OnTt3TWNcSZ06dQq1devWTf7+/kpOTtadd94p6efTXy1btlTDhg0lSfv375dhGJo0aZImTZpU5NgnT54sFN6B6wEBCLjOtG7d2nFtSXFsNluhUGS32xUcHKy33367yHWK+7C/WsHBwdqxY4dWr16tTz75RJ988okWLlyogQMHavHixdc0doHfHoUoyu233+4IVtLPR3x+fcFvgwYNFBMTI0m66667ZLVaNX78eHXq1Mkxr3a7XV26dNG4ceOK3EbBB/zVOHDggO688041btxYM2bMUHh4uDw9PbVq1Sq99NJLJf4qgaI0btxYO3bsUG5u7jV9xUBxF5P/+ghWAZvNpl69eumDDz7Qa6+9poyMDG3cuFFTp0519CnYt7Fjxyo2NrbIsevXr1/qeoHyRAACbhD16tXT2rVr1bZt2yI/0H7dT5J27dpV4g8nT09P9ezZUz179pTdbtfIkSM1b948TZo0qcixateuLUnau3ev4262Anv37nW8XxJvv/22Ll686Hhdt27dK/Z/4okn9MYbb2jixIlKSUmR9PMcnD9/3hGUilOvXj2tXr1a//vf/4o9CvTRRx8pJydHK1as0M033+xoLzjlWBZ69uypTZs26f333y/2qxB+rVq1aoW+GDE3N1cnTpwo0XZ79+6txYsXKzU1Vbt375ZhGI7TX9Ivc+/h4fG7cwlcb7gGCLhB3H///crPz9fTTz9d6L28vDzHB2LXrl1VtWpVJSUl6dKlS079DMModvwzZ844vXZzc1Pz5s0lSTk5OUWu06pVKwUHB2vu3LlOfT755BPt3r1bPXr0uKp9+7W2bdsqJibGsfxeAAoICNCwYcO0evVq7dixQ9LPc7Vp0yatXr26UP+zZ88qLy9PknTvvffKMAw99dRThfoVzFXBUatfz11mZqYWLlxY4n0rzvDhw1WzZk394x//0A8//FDo/ZMnT+qZZ55xvK5Xr57jOqYCr7/+eom/TiAmJkbVq1dXcnKykpOT1bp1a6fTZcHBwerYsaPmzZtXZLg6depUibYHVCSOAAE3iA4dOmjYsGFKSkrSjh071LVrV3l4eGjfvn167733NGvWLP3lL3+Rn5+fXnrpJQ0ZMkS33367+vbtq2rVqmnnzp26cOFCsaezhgwZov/973/q3LmzbrrpJv3444965ZVX1LJlS/3hD38och0PDw9NmzZNgwcPVocOHdSnTx/HbfAREREaM2ZMeU6Jw8MPP6yZM2fqueee05IlS/Too49qxYoVuuuuuzRo0CBFRkYqOztb//3vf7Vs2TIdOnRIgYGB6tSpkwYMGKCXX35Z+/btU7du3WS32/Xll1+qU6dOGj16tLp27eo4MjZs2DCdP39eb7zxhoKDg0t8xKU41apV0wcffKC4uDi1bNnS6Zugt23bpnfffVfR0dGO/kOGDNHw4cN17733qkuXLtq5c6dWr16twMDAEm3Xw8NDf/7zn7VkyRJlZ2frxRdfLNRn9uzZateunZo1a6ahQ4eqbt26ysjI0KZNm3T06FHt3Lnz2nYeKC+uvAUNwC8Kbkn+5ptvrtgvPj7eqFKlSrHvv/7660ZkZKTh7e1tVK1a1WjWrJkxbtw44/jx4079VqxYYbRp08bw9vY2/Pz8jNatWxvvvvuu03Z+fRv8smXLjK5duxrBwcGGp6encfPNNxvDhg0zTpw44ejz29vgCyQnJxu33nqrYbPZjOrVqxv9+vVz3Nb/e/uVmJhoXM0/VQW3lL/wwgtFvj9o0CDDarUa+/fvNwzDMM6dO2dMmDDBqF+/vuHp6WkEBgYabdq0MV588UUjNzfXsV5eXp7xwgsvGI0bNzY8PT2NoKAgo3v37sbWrVud5rJ58+aGl5eXERERYUybNs1YsGCBIclIS0tz9CvtbfAFjh8/bowZM8Zo2LCh4eXlZfj4+BiRkZHGs88+a2RmZjr65efnG4899pgRGBho+Pj4GLGxscb+/fuLvQ3+Sr9za9asMSQZFovFOHLkSJF9Dhw4YAwcONAIDQ01PDw8jLCwMOOuu+4yli1bdlX7BbiCxTCucMwbAADgBsQ1QAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHT4IsQi2O12HT9+XFWrVr3i07EBAMD1wzAMnTt3TrVq1Sr0vMTfIgAV4fjx4woPD3d1GQAAoBSOHDmim2666Yp9CEBFqFq1qqSfJ9DPz8/F1QAAgKuRlZWl8PBwx+f4lRCAilBw2svPz48ABABAJXM1l69wETQAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdlwagL774Qj179lStWrVksVj04Ycf/u4669at02233Sabzab69etr0aJFhfrMnj1bERER8vLyUlRUlLZs2VL2xQMAgErLpQEoOztbLVq00OzZs6+qf1pamnr06KFOnTppx44deuSRRzRkyBCtXr3a0Sc5OVkJCQlKTEzUtm3b1KJFC8XGxurkyZPltRsAAKCSsRiGYbi6COnnB5d98MEH6tWrV7F9HnvsMa1cuVK7du1ytD3wwAM6e/asUlJSJElRUVG6/fbb9eqrr0qS7Ha7wsPD9be//U3jx4+/qlqysrLk7++vzMzMMn0Yataly8q6eLnMxgMAmJuXh1WBvjZXl3HdKMnnd6V6GvymTZsUExPj1BYbG6tHHnlEkpSbm6utW7dqwoQJjvfd3NwUExOjTZs2FTtuTk6OcnJyHK+zsrLKtvD/96/NP+r5lL3lMjYAwJyS/txMfVrf7OoyKp1KFYDS09MVEhLi1BYSEqKsrCxdvHhRP/30k/Lz84vss2fPnmLHTUpK0lNPPVUuNf+au5tFNneuOwcAXLs8u6F8u6H/HM1Un9aurqbyqVQBqLxMmDBBCQkJjtdZWVkKDw8v8+08dEc9PXRHvTIfFwBgPq+k7tP0NT+4uoxKq1IFoNDQUGVkZDi1ZWRkyM/PT97e3rJarbJarUX2CQ0NLXZcm80mm41zqAAAmEWlOh8THR2t1NRUp7Y1a9YoOjpakuTp6anIyEinPna7XampqY4+AAAALg1A58+f144dO7Rjxw5JP9/mvmPHDh0+fFjSz6emBg4c6Og/fPhwHTx4UOPGjdOePXv02muvaenSpRozZoyjT0JCgt544w0tXrxYu3fv1ogRI5Sdna3BgwdX6L4BAIDrl0tPgX377bfq1KmT43XBdTjx8fFatGiRTpw44QhDklSnTh2tXLlSY8aM0axZs3TTTTfpn//8p2JjYx19evfurVOnTmny5MlKT09Xy5YtlZKSUujCaAAAYF7XzfcAXU/K63uAAAAoKwUXQfdpfbOS/tzM1eVcF27Y7wECAABXzzB+vlX+cr6hy3a7LufZlWc3lPv/f17Ot///Yiiv4E/7r9t+fl3Q37nPL+8XrF8wZsOQqopvE+Hq3b8iAhAAAJXYx/85rq8OnNblPLsuF4SaPLsj9LjqPE+nRsG6uYaPazZ+FQhAAABUQjdV95YknbuUp3OX8q56PaubRe5uFnla3eRutcjd6ub4u4fVTe5u//+n1SIPt1/aPawWuf//61+v6+H285/ubha5Wy1asOGQLl7O18XL+eW162WCAAQAQCXUq2WY6gX56kJuvjwcIcXNEVYKQozn/7cVBBo3N0u51pX8zZHrPvxIBCAAAColi8Wi5jcFuLqMSqtSfREiAABAWSAAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0+FZYAAAoMydOZ+jA6csOn8pT37eHqoTWMXVJTkhAAEAgDLX959fO73+YGQb3XpzNRdVUxinwAAAQJmJrhcoSXKzSH5e7vKwWiRJh/93wZVlFcIRIAAAUGZe6XOrnr+3ubw83GSxWNTvn5u1cf8ZV5dVCAEIAACUKW9Pq6tL+F2cAgMAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKZDAAIAAKbj8gA0e/ZsRUREyMvLS1FRUdqyZUuxfS9fvqwpU6aoXr168vLyUosWLZSSkuLU58knn5TFYnFaGjduXN67AQAAKhGXBqDk5GQlJCQoMTFR27ZtU4sWLRQbG6uTJ08W2X/ixImaN2+eXnnlFX3//fcaPny47rnnHm3fvt2pX9OmTXXixAnHsmHDhorYHQAAUEm4NADNmDFDQ4cO1eDBg9WkSRPNnTtXPj4+WrBgQZH933rrLT3++OOKi4tT3bp1NWLECMXFxWn69OlO/dzd3RUaGupYAgMDK2J3AABAJeGyAJSbm6utW7cqJibml2Lc3BQTE6NNmzYVuU5OTo68vLyc2ry9vQsd4dm3b59q1aqlunXrql+/fjp8+HDZ7wAAAKi0XBaATp8+rfz8fIWEhDi1h4SEKD09vch1YmNjNWPGDO3bt092u11r1qzR8uXLdeLECUefqKgoLVq0SCkpKZozZ47S0tLUvn17nTt3rthacnJylJWV5bQAAIAbl8svgi6JWbNmqUGDBmrcuLE8PT01evRoDR48WG5uv+xG9+7ddd9996l58+aKjY3VqlWrdPbsWS1durTYcZOSkuTv7+9YwsPDK2J3AACAi7gsAAUGBspqtSojI8OpPSMjQ6GhoUWuExQUpA8//FDZ2dn68ccftWfPHvn6+qpu3brFbicgIEANGzbU/v37i+0zYcIEZWZmOpYjR46UbqcAAECl4LIA5OnpqcjISKWmpjra7Ha7UlNTFR0dfcV1vby8FBYWpry8PL3//vu6++67i+17/vx5HThwQDVr1iy2j81mk5+fn9MCAABuXC49BZaQkKA33nhDixcv1u7duzVixAhlZ2dr8ODBkqSBAwdqwoQJjv5ff/21li9froMHD+rLL79Ut27dZLfbNW7cOEefsWPHav369Tp06JC++uor3XPPPbJarerTp0+F7x8AALg+ubty471799apU6c0efJkpaenq2XLlkpJSXFcGH348GGn63suXbqkiRMn6uDBg/L19VVcXJzeeustBQQEOPocPXpUffr00ZkzZxQUFKR27dpp8+bNCgoKqujdAwAA1ymLYRiGq4u43mRlZcnf31+ZmZmcDgMA4Br0++dmbdx/RrMeaKm7W4aV67ZK8vldqe4CAwAAKAsEIAAAYDouvQYIAACYw/cnspRz2a5jZy8qJ8+uv7aLUHBVr99fsZwQgAAAQLmbt/6g0+sqnlb97c4GLqqGAAQAAMpR91tqam/6OVXz8VStAG8d/emCDpzK1sXL+S6tiwAEAADKTf8/1lb/P9Z2vJ7y0fc6cCrNhRX9jIugAQCA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6bg8AM2ePVsRERHy8vJSVFSUtmzZUmzfy5cva8qUKapXr568vLzUokULpaSkXNOYAADAfFwagJKTk5WQkKDExERt27ZNLVq0UGxsrE6ePFlk/4kTJ2revHl65ZVX9P3332v48OG65557tH379lKPCQAAzMelAWjGjBkaOnSoBg8erCZNmmju3Lny8fHRggULiuz/1ltv6fHHH1dcXJzq1q2rESNGKC4uTtOnTy/1mAAAwHxcFoByc3O1detWxcTE/FKMm5tiYmK0adOmItfJycmRl5eXU5u3t7c2bNhQ6jELxs3KynJaAADAjctlAej06dPKz89XSEiIU3tISIjS09OLXCc2NlYzZszQvn37ZLfbtWbNGi1fvlwnTpwo9ZiSlJSUJH9/f8cSHh5+jXsHAACuZy6/CLokZs2apQYNGqhx48by9PTU6NGjNXjwYLm5XdtuTJgwQZmZmY7lyJEjZVQxAAC4HrksAAUGBspqtSojI8OpPSMjQ6GhoUWuExQUpA8//FDZ2dn68ccftWfPHvn6+qpu3bqlHlOSbDab/Pz8nBYAAHDjclkA8vT0VGRkpFJTUx1tdrtdqampio6OvuK6Xl5eCgsLU15ent5//33dfffd1zwmAAAwD3dXbjwhIUHx8fFq1aqVWrdurZkzZyo7O1uDBw+WJA0cOFBhYWFKSkqSJH399dc6duyYWrZsqWPHjunJJ5+U3W7XuHHjrnpMAAAAlwag3r1769SpU5o8ebLS09PVsmVLpaSkOC5iPnz4sNP1PZcuXdLEiRN18OBB+fr6Ki4uTm+99ZYCAgKuekwAAACLYRiGq4u43mRlZcnf31+ZmZlcDwQAQBma8tH3WrAxTSM71tO4bo3LdOySfH5XqrvAAAAAygIBCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmI7LA9Ds2bMVEREhLy8vRUVFacuWLVfsP3PmTDVq1Eje3t4KDw/XmDFjdOnSJcf7Tz75pCwWi9PSuHHj8t4NAABQibi7cuPJyclKSEjQ3LlzFRUVpZkzZyo2NlZ79+5VcHBwof7vvPOOxo8frwULFqhNmzb64YcfNGjQIFksFs2YMcPRr2nTplq7dq3jtbu7S3cTAABcZ1x6BGjGjBkaOnSoBg8erCZNmmju3Lny8fHRggULiuz/1VdfqW3bturbt68iIiLUtWtX9enTp9BRI3d3d4WGhjqWwMDAitgdAABQSbgsAOXm5mrr1q2KiYn5pRg3N8XExGjTpk1FrtOmTRtt3brVEXgOHjyoVatWKS4uzqnfvn37VKtWLdWtW1f9+vXT4cOHy29HAABApeOyc0OnT59Wfn6+QkJCnNpDQkK0Z8+eItfp27evTp8+rXbt2skwDOXl5Wn48OF6/PHHHX2ioqK0aNEiNWrUSCdOnNBTTz2l9u3ba9euXapatWqR4+bk5CgnJ8fxOisrqwz2EAAAXK9cfhF0Saxbt05Tp07Va6+9pm3btmn58uVauXKlnn76aUef7t2767777lPz5s0VGxurVatW6ezZs1q6dGmx4yYlJcnf39+xhIeHV8TuAAAAF3HZEaDAwEBZrVZlZGQ4tWdkZCg0NLTIdSZNmqQBAwZoyJAhkqRmzZopOztbDz30kJ544gm5uRXOcwEBAWrYsKH2799fbC0TJkxQQkKC43VWVhYhCACAG5jLjgB5enoqMjJSqampjja73a7U1FRFR0cXuc6FCxcKhRyr1SpJMgyjyHXOnz+vAwcOqGbNmsXWYrPZ5Ofn57QAAIAbl0vvD09ISFB8fLxatWql1q1ba+bMmcrOztbgwYMlSQMHDlRYWJiSkpIkST179tSMGTN06623KioqSvv379ekSZPUs2dPRxAaO3asevbsqdq1a+v48eNKTEyU1WpVnz59XLafAADg+lKqAJSfn69FixYpNTVVJ0+elN1ud3r/s88+u6pxevfurVOnTmny5MlKT09Xy5YtlZKS4rgw+vDhw05HfCZOnCiLxaKJEyfq2LFjCgoKUs+ePfXss886+hw9elR9+vTRmTNnFBQUpHbt2mnz5s0KCgoqza4CAIAbkMUo7tzRFYwePVqLFi1Sjx49VLNmTVksFqf3X3rppTIr0BWysrLk7++vzMxMTocBAFCGpnz0vRZsTNPIjvU0rlvZPqmhJJ/fpToCtGTJEi1durTQ9+8AAABUBqW6CNrT01P169cv61oAAAAqRKkC0D/+8Q/NmjWr2DuvAAAArmelOgW2YcMGff755/rkk0/UtGlTeXh4OL2/fPnyMikOAACgPJQqAAUEBOiee+4p61oAAAAqRKkC0MKFC8u6DgAAgApzTV+EeOrUKe3du1eS1KhRI75rBwAAVAqlugg6Oztbf/3rX1WzZk3dcccduuOOO1SrVi09+OCDunDhQlnXCAAAUKZKFYASEhK0fv16ffTRRzp79qzOnj2rf//731q/fr3+8Y9/lHWNAAAAZapUp8Def/99LVu2TB07dnS0xcXFydvbW/fff7/mzJlTVvUBAACUuVIdAbpw4YLjeV2/FhwczCkwAABw3StVAIqOjlZiYqIuXbrkaLt48aKeeuopRUdHl1lxAAAA5aFUp8BmzZql2NhY3XTTTWrRooUkaefOnfLy8tLq1avLtEAAAICyVqoAdMstt2jfvn16++23tWfPHklSnz591K9fP3l7e5dpgQAAAGWt1N8D5OPjo6FDh5ZlLQAAABXiqgPQihUr1L17d3l4eGjFihVX7PunP/3pmgsDAAAoL1cdgHr16qX09HQFBwerV69exfazWCzKz88vi9oAAADKxVUHILvdXuTfAQAAKptS3QZflLNnz5bVUAAAAOWqVAFo2rRpSk5Odry+7777VL16dYWFhWnnzp1lVhwAAEB5KFUAmjt3rsLDwyVJa9as0dq1a5WSkqLu3bvr0UcfLdMCAQAAylqpboNPT093BKCPP/5Y999/v7p27aqIiAhFRUWVaYEAAABlrVRHgKpVq6YjR45IklJSUhQTEyNJMgyDO8AAAMB1r1RHgP785z+rb9++atCggc6cOaPu3btLkrZv36769euXaYEAAABlrVQB6KWXXlJERISOHDmi559/Xr6+vpKkEydOaOTIkWVaIAAAQFkrVQDy8PDQ2LFjC7WPGTPmmgsCAAAobzwKAwAAmA6PwgAAAKbDozAAAIDplNmjMAAAACqLUgWgv//973r55ZcLtb/66qt65JFHrrUmAACAclWqAPT++++rbdu2hdrbtGmjZcuWXXNRAAAA5alUAejMmTPy9/cv1O7n56fTp09fc1EAAADlqVQBqH79+kpJSSnU/sknn6hu3brXXBQAAEB5KtUXISYkJGj06NE6deqUOnfuLElKTU3V9OnTNXPmzLKsDwAAoMyV6gjQX//6V02fPl3z589Xp06d1KlTJ/3rX//SnDlzNHTo0BKNNXv2bEVERMjLy0tRUVHasmXLFfvPnDlTjRo1kre3t8LDwzVmzBhdunTpmsYEAADmUurb4EeMGKGjR48qIyNDWVlZOnjwoAYOHFiiMZKTk5WQkKDExERt27ZNLVq0UGxsrE6ePFlk/3feeUfjx49XYmKidu/erfnz5ys5OVmPP/54qccEAADmU+oAlJeXp7Vr12r58uUyDEOSdPz4cZ0/f/6qx5gxY4aGDh2qwYMHq0mTJpo7d658fHy0YMGCIvt/9dVXatu2rfr27auIiAh17dpVffr0cTrCU9IxAQCA+ZQqAP34449q1qyZ7r77bo0aNUqnTp2SJE2bNq3Ih6QWJTc3V1u3blVMTMwvxbi5KSYmRps2bSpynTZt2mjr1q2OwHPw4EGtWrVKcXFxpR5TknJycpSVleW0AACAG1epAtDDDz+sVq1a6aeffpK3t7ej/Z577lFqaupVjXH69Gnl5+crJCTEqT0kJETp6elFrtO3b19NmTJF7dq1k4eHh+rVq6eOHTs6ToGVZkxJSkpKkr+/v2MJDw+/qn0AAACVU6kC0JdffqmJEyfK09PTqT0iIkLHjh0rk8KKsm7dOk2dOlWvvfaatm3bpuXLl2vlypV6+umnr2ncCRMmKDMz07EcOXKkjCoGAADXo1LdBm+324t84vvRo0dVtWrVqxojMDBQVqtVGRkZTu0ZGRkKDQ0tcp1JkyZpwIABGjJkiCSpWbNmys7O1kMPPaQnnniiVGNKks1mk81mu6q6AQBA5VeqI0Bdu3Z1+r4fi8Wi8+fPKzEx0XE9zu/x9PRUZGSk0ykzu92u1NRURUdHF7nOhQsX5ObmXLLVapUkGYZRqjEBAID5lOoI0Isvvqhu3bqpSZMmunTpkvr27at9+/YpMDBQ77777lWPk5CQoPj4eLVq1UqtW7fWzJkzlZ2drcGDB0uSBg4cqLCwMCUlJUmSevbsqRkzZujWW29VVFSU9u/fr0mTJqlnz56OIPR7YwIAAJQqAIWHh2vnzp1KTk7Wzp07df78eT344IPq16+f00XRv6d37946deqUJk+erPT0dLVs2VIpKSmOi5gPHz7sdMRn4sSJslgsmjhxoo4dO6agoCD17NlTzz777FWPCQAAYDEKvsTnKl2+fFmNGzfWxx9/rD/84Q/lVZdLZWVlyd/fX5mZmfLz83N1OQAA3DCmfPS9FmxM08iO9TSuW+MyHbskn98lvgbIw8Oj0KMnAAAAKpNSXQQ9atQoTZs2TXl5eWVdDwAAQLkr1TVA33zzjVJTU/Xpp5+qWbNmqlKlitP7y5cvL5PiAAAAykOpAlBAQIDuvffesq4FAACgQpQoANntdr3wwgv64YcflJubq86dO+vJJ58s0Z1fAAAArlaia4CeffZZPf744/L19VVYWJhefvlljRo1qrxqAwAAKBclCkBvvvmmXnvtNa1evVoffvihPvroI7399tuy2+3lVR8AAECZK1EAOnz4sNOjLmJiYmSxWHT8+PEyLwwAAKC8lCgA5eXlycvLy6nNw8NDly9fLtOiAAAAylOJLoI2DEODBg1yenL6pUuXNHz4cKdb4bkNHgAAXM9KFIDi4+MLtfXv37/MigEAAKgIJQpACxcuLK86AAAAKkypHoUBAABQmRGAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6VwXAWj27NmKiIiQl5eXoqKitGXLlmL7duzYURaLpdDSo0cPR59BgwYVer9bt24VsSsAAKAScHd1AcnJyUpISNDcuXMVFRWlmTNnKjY2Vnv37lVwcHCh/suXL1dubq7j9ZkzZ9SiRQvdd999Tv26deumhQsXOl7bbLby2wkAAFCpuPwI0IwZMzR06FANHjxYTZo00dy5c+Xj46MFCxYU2b969eoKDQ11LGvWrJGPj0+hAGSz2Zz6VatWrSJ2BwAAVAIuDUC5ubnaunWrYmJiHG1ubm6KiYnRpk2brmqM+fPn64EHHlCVKlWc2tetW6fg4GA1atRII0aM0JkzZ4odIycnR1lZWU4LAAC4cbk0AJ0+fVr5+fkKCQlxag8JCVF6evrvrr9lyxbt2rVLQ4YMcWrv1q2b3nzzTaWmpmratGlav369unfvrvz8/CLHSUpKkr+/v2MJDw8v/U4BAIDrnsuvAboW8+fPV7NmzdS6dWun9gceeMDx92bNmql58+aqV6+e1q1bpzvvvLPQOBMmTFBCQoLjdVZWFiEIAIAbmEuPAAUGBspqtSojI8OpPSMjQ6GhoVdcNzs7W0uWLNGDDz74u9upW7euAgMDtX///iLft9ls8vPzc1oAAMCNy6UByNPTU5GRkUpNTXW02e12paamKjo6+orrvvfee8rJyVH//v1/dztHjx7VmTNnVLNmzWuuGQAAVH4uvwssISFBb7zxhhYvXqzdu3drxIgRys7O1uDBgyVJAwcO1IQJEwqtN3/+fPXq1Us1atRwaj9//rweffRRbd68WYcOHVJqaqruvvtu1a9fX7GxsRWyTwAA4Prm8muAevfurVOnTmny5MlKT09Xy5YtlZKS4rgw+vDhw3Jzc85pe/fu1YYNG/Tpp58WGs9qteo///mPFi9erLNnz6pWrVrq2rWrnn76ab4LCAAASLoOApAkjR49WqNHjy7yvXXr1hVqa9SokQzDKLK/t7e3Vq9eXZblAQCAG4zLT4EBAABUNAIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwnesiAM2ePVsRERHy8vJSVFSUtmzZUmzfjh07ymKxFFp69Ojh6GMYhiZPnqyaNWvK29tbMTEx2rdvX0XsCgAAqARcHoCSk5OVkJCgxMREbdu2TS1atFBsbKxOnjxZZP/ly5frxIkTjmXXrl2yWq267777HH2ef/55vfzyy5o7d66+/vprValSRbGxsbp06VJF7RYAALiOuTwAzZgxQ0OHDtXgwYPVpEkTzZ07Vz4+PlqwYEGR/atXr67Q0FDHsmbNGvn4+DgCkGEYmjlzpiZOnKi7775bzZs315tvvqnjx4/rww8/rMA9AwAA1yuXBqDc3Fxt3bpVMTExjjY3NzfFxMRo06ZNVzXG/Pnz9cADD6hKlSqSpLS0NKWnpzuN6e/vr6ioqKseEwAA3NjcXbnx06dPKz8/XyEhIU7tISEh2rNnz++uv2XLFu3atUvz5893tKWnpzvG+O2YBe/9Vk5OjnJychyvs7KyrnofAABA5ePyU2DXYv78+WrWrJlat259TeMkJSXJ39/fsYSHh5dRhQAA4Hrk0gAUGBgoq9WqjIwMp/aMjAyFhoZecd3s7GwtWbJEDz74oFN7wXolGXPChAnKzMx0LEeOHCnprgAAgErEpQHI09NTkZGRSk1NdbTZ7XalpqYqOjr6iuu+9957ysnJUf/+/Z3a69Spo9DQUKcxs7Ky9PXXXxc7ps1mk5+fn9MCAABuXC69BkiSEhISFB8fr1atWql169aaOXOmsrOzNXjwYEnSwIEDFRYWpqSkJKf15s+fr169eqlGjRpO7RaLRY888oieeeYZNWjQQHXq1NGkSZNUq1Yt9erVq6J2CwAAXMdcHoB69+6tU6dOafLkyUpPT1fLli2VkpLiuIj58OHDcnNzPlC1d+9ebdiwQZ9++mmRY44bN07Z2dl66KGHdPbsWbVr104pKSny8vIq9/0BAADXP4thGIari7jeZGVlyd/fX5mZmZwOAwCgDE356Hst2JimkR3raVy3xmU6dkk+vyv1XWAAAAClQQACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACm4/IANHv2bEVERMjLy0tRUVHasmXLFfufPXtWo0aNUs2aNWWz2dSwYUOtWrXK8f6TTz4pi8XitDRu3Li8dwMAAFQi7q7ceHJyshISEjR37lxFRUVp5syZio2N1d69exUcHFyof25urrp06aLg4GAtW7ZMYWFh+vHHHxUQEODUr2nTplq7dq3jtbu7S3cTAABcZ1yaDGbMmKGhQ4dq8ODBkqS5c+dq5cqVWrBggcaPH1+o/4IFC/S///1PX331lTw8PCRJERERhfq5u7srNDS0XGsHAACVl8tOgeXm5mrr1q2KiYn5pRg3N8XExGjTpk1FrrNixQpFR0dr1KhRCgkJ0S233KKpU6cqPz/fqd++fftUq1Yt1a1bV/369dPhw4evWEtOTo6ysrKcFgAAcONyWQA6ffq08vPzFRIS4tQeEhKi9PT0Itc5ePCgli1bpvz8fK1atUqTJk3S9OnT9cwzzzj6REVFadGiRUpJSdGcOXOUlpam9u3b69y5c8XWkpSUJH9/f8cSHh5eNjsJAACuS5Xq4hi73a7g4GC9/vrrslqtioyM1LFjx/TCCy8oMTFRktS9e3dH/+bNmysqKkq1a9fW0qVL9eCDDxY57oQJE5SQkOB4nZWV9bshyDAM5eXlFTr6hMrJarXK3d1dFovF1aUAACqAywJQYGCgrFarMjIynNozMjKKvX6nZs2a8vDwkNVqdbT94Q9/UHp6unJzc+Xp6VlonYCAADVs2FD79+8vthabzSabzXbVtefm5urEiRO6cOHCVa+D65+Pj49q1qxZ5O8RAODG4rIA5OnpqcjISKWmpqpXr16Sfj7Ck5qaqtGjRxe5Ttu2bfXOO+/IbrfLze3ns3c//PDDFT+0zp8/rwMHDmjAgAFlUrfdbldaWpqsVqtq1aolT09PjhpUcoZhKDc3V6dOnVJaWpoaNGjg+P0CANyYXHoKLCEhQfHx8WrVqpVat26tmTNnKjs723FX2MCBAxUWFqakpCRJ0ogRI/Tqq6/q4Ycf1t/+9jft27dPU6dO1d///nfHmGPHjlXPnj1Vu3ZtHT9+XImJibJarerTp0+Z1Jybmyu73a7w8HD5+PiUyZhwPW9vb3l4eOjHH39Ubm6uvLy8XF0SAKAcuTQA9e7dW6dOndLkyZOVnp6uli1bKiUlxXFh9OHDh53+Tzw8PFyrV6/WmDFj1Lx5c4WFhenhhx/WY4895uhz9OhR9enTR2fOnFFQUJDatWunzZs3KygoqExr5wjBjYefKQCYh8svgh49enSxp7zWrVtXqC06OlqbN28udrwlS5aUVWkAAOAGxf/yAgAA0yEAmdCmTZtktVrVo0cPp/ZDhw45PUOtRo0a6tq1q7Zv317qbR0+fFg9evSQj4+PgoOD9eijjyovL++K62zbtk1dunRRQECAatSooYceekjnz5936pOamqo2bdqoatWqCg0N1WOPPVZo3NWrV+uPf/yjqlatqqCgIN177706dOhQqfcFAHDjIACZ0Pz58/W3v/1NX3zxhY4fP17o/bVr1+rEiRNavXq1zp8/r+7du+vs2bMl3k5+fr569Oih3NxcffXVV1q8eLEWLVqkyZMnF7vO8ePHFRMTo/r16+vrr79WSkqKvvvuOw0aNMjRZ+fOnYqLi1O3bt20fft2JScna8WKFU6PT0lLS9Pdd9+tzp07a8eOHVq9erVOnz6tP//5zyXeDwDADchAIZmZmYYkIzMzs9B7Fy9eNL7//nvj4sWLLqjs2p07d87w9fU19uzZY/Tu3dt49tlnHe+lpaUZkozt27c72jZu3GhIMlJSUkq8rVWrVhlubm5Genq6o23OnDmGn5+fkZOTU+Q68+bNM4KDg438/HxH23/+8x9DkrFv3z7DMAxjwoQJRqtWrZzWW7FiheHl5WVkZWUZhmEY7733nuHu7u40zooVKwyLxWLk5uYWue3K/rMFgMrgqRXfGbUf+9iY9snuMh/7Sp/fv8URoDJgGIYu5OZV+GIYRolrXbp0qRo3bqxGjRqpf//+WrBgwRXH8fb2lvTz7f+SNHz4cPn6+l5xKbBp0yY1a9bM6XEnsbGxysrK0nfffVfk9nJycuTp6el0R1ZBDRs2bHD0+e1t6t7e3rp06ZK2bt0qSYqMjJSbm5sWLlyo/Px8ZWZm6q233lJMTIzjQboAAPNy+V1gN4KLl/PVZPLqCt/u91Ni5eNZsh/h/Pnz1b9/f0lSt27dlJmZqfXr16tjx46F+p49e1ZPP/20fH191bp1a0nSlClTNHbs2KvaVnp6epHPeit4ryidO3dWQkKCXnjhBT388MPKzs52nNo6ceKEpJ9D1MyZM/Xuu+/q/vvvV3p6uqZMmeLUp06dOvr00091//33a9iwYcrPz1d0dLRWrVp1VbUDAG5sHAEykb1792rLli2OL4V0d3dX7969NX/+fKd+bdq0ka+vr6pVq6adO3cqOTnZEVyCg4NVv379Ky7XomnTplq8eLGmT58uHx8fhYaGqk6dOgoJCXEcFeratateeOEFDR8+XDabTQ0bNlRcXJykX77LJz09XUOHDlV8fLy++eYbrV+/Xp6envrLX/5SqiNnAIAbC0eAyoC3h1XfT4l1yXZLYv78+crLy1OtWrUcbYZhyGaz6dVXX3W0JScnq0mTJqpRo4YCAgKcxhg+fLj+9a9/XXE7BXdshYaGasuWLU7vFTz7rbjnvUlS37591bdvX2VkZKhKlSqyWCyaMWOG6tat6+iTkJCgMWPG6MSJE6pWrZoOHTqkCRMmOPrMnj1b/v7+ev755x3r/Otf/1J4eLi+/vpr/fGPf7ziPgAAbmwEoDJgsVhKfCqqouXl5enNN9/U9OnT1bVrV6f3evXqpXfffVfdunWT9PM3bterV6/IcUpyCiw6OlrPPvusTp48qeDgYEnSmjVr5OfnpyZNmvzu+gVHnRYsWCAvLy916dLF6X2LxeIIc++++67Cw8N12223SZIuXLhQ6JudCx6ia7fbr6p+AMCN6/r+1EaZ+fjjj/XTTz/pwQcflL+/v9N79957r+bPn+8IQFcSHBzsCDO/p2vXrmrSpIkGDBig559/Xunp6Zo4caJGjRolm80mSdqyZYsGDhyo1NRUhYWFSZJeffVVx2m4NWvW6NFHH9Vzzz3ndDTqhRdeULdu3eTm5qbly5frueee09KlSx0hp0ePHnrppZc0ZcoU9enTR+fOndPjjz+u2rVr69Zbb72q+gEANy6uATKJ+fPnKyYmplD4kX4OQN9++62ysrLKdJtWq1Uff/yxrFaroqOj1b9/fw0cONBxwbL085GavXv36vLly462LVu2qEuXLmrWrJlef/11zZs3z+mBt5L0ySefqH379mrVqpVWrlypf//73+rVq5fj/c6dO+udd97Rhx9+qFtvvVXdunWTzWZTSkqK464yAEDF87BaZHN3k7ubxaV1WAyuCC0kKytL/v7+yszMlJ+fn9N7ly5dUlpamurUqcMTw28w/GwBoHK70uf3b3EECAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BqJS4ee7Gw88UAMyDAFRCBU8Sv3DhgosrQVkr+JnytHgAuPHxTdAlZLVaFRAQoJMnT0qSfHx8ZLG49succG0Mw9CFCxd08uRJBQQEOL5NGgBw4yIAlULBgzwLQhBuDAEBAVd8SCsA4MZBACoFi8WimjVrKjg42OkRDqi8PDw8OPIDACZCALoGVquVD00AACohLoIGAACmQwACAACmQwACAACmwzVARSj4QrysrCwXVwIAAK5Wwef21XyxLQGoCOfOnZMkhYeHu7gSAABQUufOnZO/v/8V+1gMvv+/ELvdruPHj6tq1apl/iWHWVlZCg8P15EjR+Tn51emY+MXzHPFYJ4rBvNcMZjnilGe82wYhs6dO6datWrJze3KV/lwBKgIbm5uuummm8p1G35+fvwHVgGY54rBPFcM5rliMM8Vo7zm+feO/BTgImgAAGA6BCAAAGA6BKAKZrPZlJiYKJvN5upSbmjMc8VgnisG81wxmOeKcb3MMxdBAwAA0+EIEAAAMB0CEAAAMB0CEAAAMB0CEAAAMB0CUDmYPXu2IiIi5OXlpaioKG3ZsuWK/d977z01btxYXl5eatasmVatWlVBlVZuJZnnN954Q+3bt1e1atVUrVo1xcTE/O7PBT8r6e9zgSVLlshisahXr17lW+ANoqTzfPbsWY0aNUo1a9aUzWZTw4YN+bfjKpR0nmfOnKlGjRrJ29tb4eHhGjNmjC5dulRB1VZOX3zxhXr27KlatWrJYrHoww8//N111q1bp9tuu002m03169fXokWLyr1OGShTS5YsMTw9PY0FCxYY3333nTF06FAjICDAyMjIKLL/xo0bDavVajz//PPG999/b0ycONHw8PAw/vvf/1Zw5ZVLSee5b9++xuzZs43t27cbu3fvNgYNGmT4+/sbR48ereDKK5eSznOBtLQ0IywszGjfvr1x9913V0yxlVhJ5zknJ8do1aqVERcXZ2zYsMFIS0sz1q1bZ+zYsaOCK69cSjrPb7/9tmGz2Yy3337bSEtLM1avXm3UrFnTGDNmTAVXXrmsWrXKeOKJJ4zly5cbkowPPvjgiv0PHjxo+Pj4GAkJCcb3339vvPLKK4bVajVSUlLKtU4CUBlr3bq1MWrUKMfr/Px8o1atWkZSUlKR/e+//36jR48eTm1RUVHGsGHDyrXOyq6k8/xbeXl5RtWqVY3FixeXV4k3hNLMc15entGmTRvjn//8pxEfH08Augolnec5c+YYdevWNXJzcyuqxBtCSed51KhRRufOnZ3aEhISjLZt25ZrnTeSqwlA48aNM5o2berU1rt3byM2NrYcKzMMToGVodzcXG3dulUxMTGONjc3N8XExGjTpk1FrrNp0yan/pIUGxtbbH+Ubp5/68KFC7p8+bKqV69eXmVWeqWd5ylTpig4OFgPPvhgRZRZ6ZVmnlesWKHo6GiNGjVKISEhuuWWWzR16lTl5+dXVNmVTmnmuU2bNtq6davjNNnBgwe1atUqxcXFVUjNZuGqz0EehlqGTp8+rfz8fIWEhDi1h4SEaM+ePUWuk56eXmT/9PT0cquzsivNPP/WY489plq1ahX6jw6/KM08b9iwQfPnz9eOHTsqoMIbQ2nm+eDBg/rss8/Ur18/rVq1Svv379fIkSN1+fJlJSYmVkTZlU5p5rlv3746ffq02rVrJ8MwlJeXp+HDh+vxxx+viJJNo7jPwaysLF28eFHe3t7lsl2OAMF0nnvuOS1ZskQffPCBvLy8XF3ODePcuXMaMGCA3njjDQUGBrq6nBua3W5XcHCwXn/9dUVGRqp379564oknNHfuXFeXdkNZt26dpk6dqtdee03btm3T8uXLtXLlSj399NOuLg1lgCNAZSgwMFBWq1UZGRlO7RkZGQoNDS1yndDQ0BL1R+nmucCLL76o5557TmvXrlXz5s3Ls8xKr6TzfODAAR06dEg9e/Z0tNntdkmSu7u79u7dq3r16pVv0ZVQaX6fa9asKQ8PD1mtVkfbH/7wB6Wnpys3N1eenp7lWnNlVJp5njRpkgYMGKAhQ4ZIkpo1a6bs7Gw99NBDeuKJJ+TmxjGEslDc56Cfn1+5Hf2ROAJUpjw9PRUZGanU1FRHm91uV2pqqqKjo4tcJzo62qm/JK1Zs6bY/ijdPEvS888/r6efflopKSlq1apVRZRaqZV0nhs3bqz//ve/2rFjh2P505/+pE6dOmnHjh0KDw+vyPIrjdL8Prdt21b79+93BExJ+uGHH1SzZk3CTzFKM88XLlwoFHIKQqfBYzTLjMs+B8v1EmsTWrJkiWGz2YxFixYZ33//vfHQQw8ZAQEBRnp6umEYhjFgwABj/Pjxjv4bN2403N3djRdffNHYvXu3kZiYyG3wV6Gk8/zcc88Znp6exrJly4wTJ044lnPnzrlqFyqFks7zb3EX2NUp6TwfPnzYqFq1qjF69Ghj7969xscff2wEBwcbzzzzjKt2oVIo6TwnJiYaVatWNd59913j4MGDxqeffmrUq1fPuP/++121C5XCuXPnjO3btxvbt283JBkzZswwtm/fbvz444+GYRjG+PHjjQEDBjj6F9wG/+ijjxq7d+82Zs+ezW3wldUrr7xi3HzzzYanp6fRunVrY/PmzY73OnToYMTHxzv1X7p0qdGwYUPD09PTaNq0qbFy5coKrrhyKsk8165d25BUaElMTKz4wiuZkv4+/xoB6OqVdJ6/+uorIyoqyrDZbEbdunWNZ5991sjLy6vgqiufkszz5cuXjSeffNKoV6+e4eXlZYSHhxsjR440fvrpp4ovvBL5/PPPi/z3tmBu4+PjjQ4dOhRap2XLloanp6dRt25dY+HCheVep8UwOI4HAADMhWuAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAACA6RCAAOAqWSwWffjhh5KkQ4cOyWKxaMeOHS6tCUDpEIAAVAqDBg2SxWKRxWKRh4eH6tSpo3HjxunSpUuuLg1AJcTT4AFUGt26ddPChQt1+fJlbd26VfHx8bJYLJo2bZqrSwNQyXAECEClYbPZFBoaqvDwcPXq1UsxMTFas2aNpJ+f7J2UlKQ6derI29tbLVq00LJly5zW/+6773TXXXfJz89PVatWVfv27XXgwAFJ0jfffKMuXbooMDBQ/v7+6tChg7Zt21bh+wigYhCAAFRKu3bt0ldffSVPT09JUlJSkt58803NnTtX3333ncaMGaP+/ftr/fr1kqRjx47pjjvukM1m02effaatW7fqr3/9q/Ly8iRJ586dU3x8vDZs2KDNmzerQYMGiouL07lz51y2jwDKD6fAAFQaH3/8sXx9fZWXl6ecnBy5ubnp1VdfVU5OjqZOnaq1a9cqOjpaklS3bl1t2LBB8+bNU4cOHTR79mz5+/tryZIl8vDwkCQ1bNjQMXbnzp2dtvX6668rICBA69ev11133VVxOwmgQhCAAFQanTp10pw5c5Sdna2XXnpJ7u7uuvfee/Xdd9/pwoUL6tKli1P/3Nxc3XrrrZKkHTt2qH379o7w81sZGRmaOHGi1q1bp5MnTyo/P18XLlzQ4cOHy32/AFQ8AhCASqNKlSqqX7++JGnBggVq0aKF5s+fr1tuuUWStHLlSoWFhTmtY7PZJEne3t5XHDs+Pl5nzpzRrFmzVLt2bdlsNkVHRys3N7cc9gSAqxGAAFRKbm5uevzxx5WQkKAffvhBNptNhw8fVocOHYrs37x5cy1evFiXL18u8ijQxo0b9dprrykuLk6SdOTIEZ0+fbpc9wGA63ARNIBK67777pPVatW8efM0duxYjRkzRosXL9aBAwe0bds2vfLKK1q8eLEkafTo0crKytIDDzygb7/9Vvv27dNbb72lvXv3SpIaNGigt956S7t379bXX3+tfv36/e5RIwCVF0eAAFRa7u7uGj16tJ5//nmlpaUpKChISUlJOnjwoAICAnTbbbfp8ccflyTVqFFDn332mR599FF16NBBVqtVLVu2VNu2bSVJ8+fP10MPPaTbbrtN4eHhmjp1qsaOHevK3QNQjiyGYRiuLgIAAKAicQoMAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYzv8B6U5reqqbPhAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy"
      ],
      "metadata": {
        "id": "xVlO4Nxv2fXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "estimators = [('rf', RandomForestClassifier(n_estimators=50, random_state=42))]\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=1000), n_jobs=-1)\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking accuracy:\", round(accuracy_score(y_test, stack.predict(X_test)), 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-cfW_Ur9PBx",
        "outputId": "9f79a360-8628-44ae-f669-1a3a6cb5dec3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance"
      ],
      "metadata": {
        "id": "KsRrDtbE2hk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = make_regression(n_samples=800, n_features=15, noise=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "for max_samples in [0.5, 0.7, 1.0]:\n",
        "    bag = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42), n_estimators=50,\n",
        "                           max_samples=max_samples, random_state=42)\n",
        "    bag.fit(X_train, y_train)\n",
        "    print(f\"max_samples={max_samples} -> MSE: {mean_squared_error(y_test, bag.predict(X_test)):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU2Mp9bs9Q6a",
        "outputId": "f7afc61f-e2f9-4885-f3e0-89106198fa9f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_samples=0.5 -> MSE: 6867.9262\n",
            "max_samples=0.7 -> MSE: 7062.2823\n",
            "max_samples=1.0 -> MSE: 6401.7939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "WJXYwyYm0dHP"
      },
      "outputs": [],
      "source": []
    }
  ]
}